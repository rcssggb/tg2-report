%TCIDATA{LaTeXparent=0,0,these.tex}


%\chapter*{\setfontarial\mdseries LISTA DE SÍMBOLOS} % se usar ft1unb.sty, descomente esta linha



\chapter*{LISTA DE SÍMBOLOS}

% se usar ft2unb.sty, descomente esta linha

\subsection*{Símbolos latinos}

\begin{tabular}{p{0.1\textwidth}p{0.63\textwidth}>{\PreserveBacklash\raggedleft}p{0.15\textwidth}}
	$S$ & Estado \tabularnewline
	$A$ & Ação \tabularnewline
	$R$ & Recompensa \tabularnewline
	$G$ & Retorno \tabularnewline
	$v$ & Função de valor \tabularnewline
	$q$ & Função de valor da ação\tabularnewline
 \end{tabular}

\subsection*{Símbolos gregos}

\begin{tabular}{p{0.1\textwidth}p{0.63\textwidth}>{\PreserveBacklash\raggedleft}p{0.15\textwidth}}
$\pi$ & Política de tomada de ação \tabularnewline
$\gamma$ & Fator de desconto \tabularnewline
$\alpha$ & Fator de aprendizagem \tabularnewline
$\epsilon$ & Fator de exploração \tabularnewline
$\theta_j$ & Ângulo absoluto do jogador \tabularnewline
\end{tabular}

\subsection*{Subscritos}

\begin{tabular}{p{0.1\textwidth}p{0.8\textwidth}}
$t$  & Ciclo $t$ de treinamento \tabularnewline
$terminal$  & Ciclo que encerra episódio \tabularnewline
$v_\pi$ ou  $q_\pi$ & Função de esperança do retorno de acordo com a política $\pi$ \tabularnewline
$*$  & Política ótima \tabularnewline
\end{tabular}

\subsection*{Siglas}

\begin{tabular}{p{0.1\textwidth}p{0.8\textwidth}}
IA  & Inteligência artificial\tabularnewline
RL & Aprendizagem por reforço - \textit{Reinforcement learning} \tabularnewline
RCSS & \textit{RoboCup Soccer Simulation 2D}\tabularnewline
LARC & \textit{Latin American Robotics Competition} \tabularnewline
UDP & \textit{User Datagram Protocol}\tabularnewline
MDP & Processo de decisão de Markov - \textit{Markov decision process}\tabularnewline
GPI & \textit{Generalized policy iteration} \tabularnewline

\end{tabular}
